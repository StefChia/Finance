{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STANDARD PORTFOLIO OPTIMIZATION \n",
    "\n",
    "With cvxpy.\n",
    "\n",
    "Portfolio selection via:\n",
    "-MeanVariance\n",
    "-risk parity portfolio\n",
    "\n",
    "Expected Values estimated via:\n",
    "-zero assumption\n",
    "-sample mean\n",
    "-trading signals (e.g. sentiment analysis)\n",
    "\n",
    "Varcov estimated via:\n",
    "- sample variance\n",
    "- sample variance de-noised via estimation within PCs Factor Model\n",
    "- EWMA (on PCs and residuals)\n",
    "\n",
    "Additional steps:\n",
    "-think about model correlation DCC models and GARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Risk Parity Portfolio\n",
    "\n",
    "- **Returns covariance matrix**  \n",
    "  $$\n",
    "  \\Sigma \\in \\mathbb{R}^{N \\times N}\n",
    "  $$\n",
    "\n",
    "- **Portfolio weights**  \n",
    "  $$\n",
    "  w \\in \\mathbb{R}^N, \\quad \\sum_{i=1}^N w_i = 1, \\quad w_i \\geq 0\n",
    "  $$\n",
    "\n",
    "- **Portfolio variance**  \n",
    "  $$\n",
    "  \\sigma_p^2 = w^\\top \\Sigma w\n",
    "  $$\n",
    "\n",
    "- **Marginal contribution of asset $i$**  \n",
    "  $$\n",
    "  \\text{MRC}_i = \\frac{\\partial \\sigma_p}{\\partial w_i} \n",
    "  = \\frac{(\\Sigma w)_i}{\\sigma_p}\n",
    "  $$\n",
    "\n",
    "- **Risk contribution of asset $i$**  \n",
    "  $$\n",
    "  \\text{RC}_i = w_i \\cdot \\text{MRC}_i \n",
    "  = \\frac{w_i (\\Sigma w)_i}{\\sigma_p}\n",
    "  $$\n",
    "\n",
    "- **Risk parity condition**  \n",
    "  $$\n",
    "  \\text{RC}_1 = \\text{RC}_2 = \\cdots = \\text{RC}_N\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Why it’s actually exact\n",
    "\n",
    "Volatility is\n",
    "\n",
    "$$\n",
    "\\sigma_p(w) = \\sqrt{w^\\top \\Sigma w}.\n",
    "$$\n",
    "\n",
    "This is a **homogeneous function of degree 1** in $w$:  \n",
    "if you scale $w$ by $c$, volatility scales by $|c|$.\n",
    "\n",
    "---\n",
    "\n",
    "For any homogeneous degree-1 function $f$,  \n",
    "**Euler’s homogeneous function theorem** says:\n",
    "\n",
    "$$\n",
    "f(w) = \\sum_{i=1}^N w_i \\, \\frac{\\partial f(w)}{\\partial w_i}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Apply this to $f(w) = \\sigma_p(w)$:\n",
    "\n",
    "$$\n",
    "\\sigma_p = \\sum_{i=1}^N w_i \\cdot \\text{MRC}_i.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Now divide through by $\\sigma_p$, and you get the exact decomposition into risk contributions:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N \\text{RC}_i \n",
    "= \\sum_{i=1}^N \\frac{w_i \\cdot \\text{MRC}_i}{\\sigma_p} \n",
    "= 1.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "So risk contributions (RCs) aren’t a linear approximation,  \n",
    "they’re an **exact partition of total risk**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EWMA on Returns vs. EWMA on Principal Components\n",
    "\n",
    "## 1. EWMA directly on returns\n",
    "We update the full covariance matrix directly:\n",
    "$$\n",
    "\\Sigma_t = \\lambda \\Sigma_{t-1} + (1-\\lambda) r_t r_t^\\top,\n",
    "$$\n",
    "where $r_t \\in \\mathbb{R}^N$ is the vector of returns.\n",
    "\n",
    "- Pros: simple, captures variances and covariances dynamically.  \n",
    "- Cons: updates $O(N^2)$ parameters per step using only $N$ observations.  \n",
    "  → Noisy and unstable in high dimension.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. EWMA on Principal Components (factorized approach)\n",
    "Decompose returns via PCA:\n",
    "$$\n",
    "r_t = L f_t + \\epsilon_t,\n",
    "$$\n",
    "where $f_t \\in \\mathbb{R}^k$ are the top $k$ principal components,  \n",
    "$L \\in \\mathbb{R}^{N \\times k}$ is the loading matrix, and $\\epsilon_t$ are residuals.\n",
    "\n",
    "- Apply EWMA only to factor returns $f_t$:\n",
    "$$\n",
    "\\Sigma_{f,t} = \\lambda \\Sigma_{f,t-1} + (1-\\lambda) f_t f_t^\\top,\n",
    "$$\n",
    "\n",
    "- Model residual variances with diagonal EWMA:\n",
    "$$\n",
    "\\Sigma_{\\epsilon,t} = \\mathrm{diag}(\\sigma^2_{\\epsilon,1,t}, \\dots, \\sigma^2_{\\epsilon,N,t}).\n",
    "$$\n",
    "\n",
    "- Reconstruct total covariance:\n",
    "$$\n",
    "\\Sigma_t = L \\, \\Sigma_{f,t} L^\\top + \\Sigma_{\\epsilon,t}.\n",
    "$$\n",
    "\n",
    "- Pros: dimension reduction, more robust estimation, mimics industry risk models.  \n",
    "- Cons: depends on factor specification, PCA loadings must be recomputed periodically.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Rule of Thumb\n",
    "- Small universe ($N < 15$): use EWMA directly on returns.  \n",
    "- Medium/large universe ($N > 30$): EWMA on PCs/factors is more stable.  \n",
    "- Very large universes ($N \\gg 100$): factor models are the only feasible option.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting the One-Step Ahead Covariance Matrix\n",
    "\n",
    "## 1. Baseline: DCC–GARCH\n",
    "For a universe of assets $r_{i,t}$, the **Dynamic Conditional Correlation (DCC)–GARCH** model is a standard choice.\n",
    "\n",
    "### Step A: Univariate GARCH\n",
    "For each asset $i$:\n",
    "$$\n",
    "r_{i,t} = \\sigma_{i,t} z_{i,t}, \\quad z_{i,t} \\sim \\text{i.i.d.}(0,1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_{i,t}^2 = \\omega_i + \\alpha_i r_{i,t-1}^2 + \\beta_i \\sigma_{i,t-1}^2\n",
    "$$\n",
    "\n",
    "### Step B: DCC correlations\n",
    "Let $z_t = (z_{1,t}, \\dots, z_{N,t})^\\top$ be standardized residuals.\n",
    "$$\n",
    "Q_t = (1-a-b)\\bar{Q} + a z_{t-1}z_{t-1}^\\top + b Q_{t-1},\n",
    "$$\n",
    "\n",
    "$$\n",
    "R_t = \\text{diag}(Q_t)^{-\\tfrac{1}{2}} Q_t \\text{diag}(Q_t)^{-\\tfrac{1}{2}}\n",
    "$$\n",
    "\n",
    "### Step C: Combine\n",
    "The 1-step-ahead covariance matrix is:\n",
    "$$\n",
    "\\Sigma_{t+1} = D_{t+1} R_{t+1} D_{t+1},\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "D_{t+1} = \\mathrm{diag}(\\sigma_{1,t+1}, \\dots, \\sigma_{N,t+1})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Scaling Issues\n",
    "- If $N \\lesssim 30$: full DCC–GARCH is feasible.  \n",
    "- If $N$ is large: estimation error dominates. Use **Factor-GARCH / PCA–DCC**:\n",
    "  - Run PCA on returns, keep top $k$ factors.  \n",
    "  - Fit GARCH/DCC on factor series.  \n",
    "  - Model idiosyncratic risks with diagonal EWMA/GARCH.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Alternatives\n",
    "- **High-frequency data:** use realized volatility / HAR-RV + DCC.  \n",
    "- **Simpler robust option:** EWMA on factors + diagonal EWMA for residuals.  \n",
    "- **Shrinkage methods:** Dynamic Ledoit–Wolf or POET for large $N$.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Evaluation Checklist\n",
    "- Forecast loss:\n",
    "$$\n",
    "L = \\big(\\hat\\sigma_{p,t+1}^2 - r_{p,t+1}^2\\big)^2\n",
    "$$\n",
    "for target portfolios.  \n",
    "\n",
    "- Out-of-sample realized volatility of optimized portfolios.  \n",
    "- Stability and turnover of portfolio weights.  \n",
    "- Diebold–Mariano tests for forecast comparison.  \n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "- DCC–GARCH is a strong 1-step-ahead $\\Sigma_{t+1}$ forecaster for moderate universes.  \n",
    "- For large $N$, prefer **factor + DCC** or **shrinkage-based estimators**.  \n",
    "- Realized volatility models dominate if high-frequency data is available.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
